store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.5759, 'nll': 2.0945358281646693, 'entropy': 0.6982294816004528}, 'active_entropy': 0.732256270853341, 'chosen_targets': [3, 0, 0, 9, 2, 4, 4, 4, 0, 3], 'chosen_samples': [2149, 32109, 51598, 36282, 4701, 45794, 46623, 48959, 12748, 18243], 'chosen_samples_score': [1.3542470219979603, 1.4739539940817548, 1.5964145706861432, 1.6084824515312075, 1.6093153881815625, 1.598520293498251, 1.61668462226567, 1.6125983170571248, 1.6163204767827408, 1.6188698677469269], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 8.06161225300093, 'batch_acquisition_elapsed_time': 285.81976029900034, 'prior_pool_entropy': 0.8305200132804963, 'batch_pool_mi': 0.42777071194952343})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6904, 'nll': 1.2119699190854112, 'entropy': 0.6837337194650964}, 'active_entropy': 0.6921178081495389, 'chosen_targets': [6, 5, 5, 6, 3, 5, 7, 5, 6, 7], 'chosen_samples': [165, 7244, 46996, 31924, 48355, 32393, 43461, 33700, 40642, 18910], 'chosen_samples_score': [1.0516832275160908, 1.323585951809148, 1.5562589842546477, 1.6016606605035846, 1.608677027301577, 1.6214213611127444, 1.6105818075077516, 1.6036295303600396, 1.6020487810790867, 1.5987598343426574], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.394243787999585, 'batch_acquisition_elapsed_time': 259.86113820000173, 'prior_pool_entropy': 0.7750501026383657, 'batch_pool_mi': 0.4023552003965186})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7775, 'nll': 0.850376104937413, 'entropy': 0.5933610955561142}, 'active_entropy': 0.6239582707642674, 'chosen_targets': [8, 8, 3, 2, 8, 2, 2, 1, 9, 9], 'chosen_samples': [2170, 6604, 16549, 10616, 40571, 28631, 8277, 36273, 40317, 3483], 'chosen_samples_score': [1.3190877098528393, 1.58470406660698, 1.6084199175557303, 1.609362228198174, 1.6094338721994115, 1.6079933645208904, 1.6178630882225118, 1.6102751578772478, 1.6124699366123565, 1.6084954669126028], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.735065881999617, 'batch_acquisition_elapsed_time': 256.7774134629981, 'prior_pool_entropy': 0.7334466080443969, 'batch_pool_mi': 0.3241740796051604})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7753, 'nll': 0.8162844501939692, 'entropy': 0.5386972906212311}, 'active_entropy': 0.4757046133604643, 'chosen_targets': [0, 5, 6, 7, 2, 8, 0, 0, 4, 6], 'chosen_samples': [1029, 19396, 53909, 36531, 50705, 3066, 24440, 39656, 35946, 4533], 'chosen_samples_score': [1.1825853629100225, 1.2393238475696116, 1.5765746109413654, 1.6048477890197916, 1.608738182520291, 1.61236079751987, 1.5985631190108802, 1.6204611932441852, 1.6133740508945928, 1.610863063707142], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.127355855001952, 'batch_acquisition_elapsed_time': 258.03251552000074, 'prior_pool_entropy': 0.5968086789649755, 'batch_pool_mi': 0.27797137851179327})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8244, 'nll': 0.6223547961239945, 'entropy': 0.5399834398724993}, 'active_entropy': 0.557829609409325, 'chosen_targets': [0, 2, 6, 2, 2, 2, 4, 3, 6, 5], 'chosen_samples': [1725, 55545, 30083, 34558, 34856, 18927, 29291, 34740, 18608, 24202], 'chosen_samples_score': [1.1416115864260996, 1.255017406560548, 1.5898241888050761, 1.6060786456754852, 1.6091206998190364, 1.617002730956834, 1.6040769770459682, 1.6134151559839562, 1.6132463785561422, 1.609561431340147], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.123515284998575, 'batch_acquisition_elapsed_time': 256.36230702800094, 'prior_pool_entropy': 0.5957774271011644, 'batch_pool_mi': 0.28956746990857035})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.824, 'nll': 0.624759740317428, 'entropy': 0.5270198164614083}, 'active_entropy': 0.48084404062166625, 'chosen_targets': [7, 4, 5, 8, 2, 2, 2, 5, 2, 8], 'chosen_samples': [436, 1160, 51231, 27323, 4153, 45430, 52169, 17461, 42491, 41013], 'chosen_samples_score': [1.2558786693440571, 1.3094985537528183, 1.5978533107523691, 1.607294722260527, 1.6090877077660002, 1.6058254034934185, 1.616376624966168, 1.6136226127771542, 1.5989046521136792, 1.6150555590307287], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.0207408649985155, 'batch_acquisition_elapsed_time': 261.18923906000055, 'prior_pool_entropy': 0.42944972913122664, 'batch_pool_mi': 0.19691906192909697})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8231, 'nll': 0.6373948711614978, 'entropy': 0.5625264120391226}, 'active_entropy': 0.5205192672417439, 'chosen_targets': [3, 2, 6, 3, 5, 8, 8, 7, 3, 8], 'chosen_samples': [1428, 25246, 33812, 12656, 12181, 28181, 20709, 14598, 5088, 56617], 'chosen_samples_score': [1.0567871637404536, 1.4721154642598764, 1.599807551520546, 1.6081872870247365, 1.6093319699704525, 1.6116199097609158, 1.6269715615865232, 1.6135050378061844, 1.60373006521707, 1.6027886367680613], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.035161503001291, 'batch_acquisition_elapsed_time': 256.2109066890007, 'prior_pool_entropy': 0.6634434837138763, 'batch_pool_mi': 0.2504992032841758})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8542, 'nll': 0.5274532888836254, 'entropy': 0.6161032093111823}, 'active_entropy': 0.6191788913177539, 'chosen_targets': [3, 3, 7, 4, 3, 3, 2, 3, 0, 2], 'chosen_samples': [811, 41123, 28723, 9781, 19169, 24931, 25658, 49188, 47914, 43040], 'chosen_samples_score': [1.0500227525136077, 1.443647641626327, 1.5869464906546296, 1.6057401574109826, 1.6088323839461023, 1.6074728014182045, 1.6134552174585783, 1.6016440723434484, 1.6170110280500039, 1.6189400223543595], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.007083065000188, 'batch_acquisition_elapsed_time': 260.35437052699854, 'prior_pool_entropy': 0.761641356951092, 'batch_pool_mi': 0.39796437689729625})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8252, 'nll': 0.6049018940737315, 'entropy': 0.5603914240720181}, 'active_entropy': 0.5327183916781228, 'chosen_targets': [3, 3, 8, 4, 5, 8, 1, 4, 3, 9], 'chosen_samples': [856, 670, 46776, 33846, 32290, 39778, 33856, 34429, 37065, 35125], 'chosen_samples_score': [0.9625194886606347, 1.3925293897964615, 1.5577933794480523, 1.5948633245749921, 1.6056364857516412, 1.5969230008450424, 1.6087266242837326, 1.597556994560291, 1.6061069814192162, 1.576770446540341], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 4.953306513001735, 'batch_acquisition_elapsed_time': 260.16698046799866, 'prior_pool_entropy': 0.4979326274519017, 'batch_pool_mi': 0.24713545586219082})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8631, 'nll': 0.4951043052592653, 'entropy': 0.628820072193483}, 'active_entropy': 0.7034463165845062, 'chosen_targets': [7, 7, 2, 5, 3, 3, 8, 7, 2, 7], 'chosen_samples': [141, 22167, 54987, 39405, 13894, 1260, 29132, 38688, 37601, 20226], 'chosen_samples_score': [0.9879240398765471, 1.3063683266302366, 1.5674539487457517, 1.6021212695969629, 1.608284013925887, 1.606360819048918, 1.6071598713136397, 1.6094290144642018, 1.5948665527828378, 1.6125571844732685], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.028531174000818, 'batch_acquisition_elapsed_time': 260.26350303800064, 'prior_pool_entropy': 0.6753414595825094, 'batch_pool_mi': 0.4142158326393351})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8691, 'nll': 0.4765742183512649, 'entropy': 0.5611429042665366}, 'active_entropy': 0.4612087554978847, 'chosen_targets': [1, 8, 5, 9, 6, 0, 6, 9, 2, 0], 'chosen_samples': [14, 33162, 31545, 36186, 30856, 12497, 5684, 58242, 16716, 46339], 'chosen_samples_score': [0.9718775560683831, 1.264618582445093, 1.5436548158923982, 1.6000109661862076, 1.6075769513408744, 1.6084331328340224, 1.6170697799671931, 1.601233439560605, 1.5887245017524005, 1.605446805011434], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.05635300600261, 'batch_acquisition_elapsed_time': 261.440820926, 'prior_pool_entropy': 0.5198466020059688, 'batch_pool_mi': 0.2127163536945275})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8917, 'nll': 0.42080045519419484, 'entropy': 0.5897308681575592}, 'active_entropy': 0.5039974228811028, 'chosen_targets': [6, 7, 8, 5, 7, 4, 7, 8, 5, 5], 'chosen_samples': [1323, 16882, 27646, 10286, 55802, 18398, 18962, 59343, 29120, 18573], 'chosen_samples_score': [0.9803748379897598, 1.127422188586411, 1.4715496202766785, 1.5801842009463287, 1.5995682576699581, 1.5948254073495596, 1.6026922871664033, 1.6254572150137552, 1.6027031094544215, 1.6084003197792347], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.026109413000086, 'batch_acquisition_elapsed_time': 259.7069531369998, 'prior_pool_entropy': 0.5393177689494669, 'batch_pool_mi': 0.3021719667944192})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8772, 'nll': 0.4351499181971446, 'entropy': 0.6219411269174651}, 'active_entropy': 0.6868303545441896, 'chosen_targets': [1, 8, 2, 8, 8, 9, 8, 8, 2, 7], 'chosen_samples': [124, 57348, 34308, 4873, 36854, 57728, 48494, 48973, 24968, 1127], 'chosen_samples_score': [1.0502493318404318, 1.2767797935529868, 1.5330398742869487, 1.5959703807353924, 1.6064948218965251, 1.5998154484936498, 1.5929484178749833, 1.5951605071079893, 1.624360737479793, 1.6110254148496397], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.02096431300015, 'batch_acquisition_elapsed_time': 260.57700917200054, 'prior_pool_entropy': 0.6502691656171011, 'batch_pool_mi': 0.41578637067331725})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8825, 'nll': 0.45954762939804833, 'entropy': 0.6532100310633456}, 'active_entropy': 0.7222149091307878, 'chosen_targets': [3, 1, 4, 9, 1, 4, 8, 4, 4, 7], 'chosen_samples': [2180, 44245, 35472, 626, 59783, 43010, 42384, 56334, 5293, 1075], 'chosen_samples_score': [1.034858307280146, 1.1625661173210018, 1.5148122527055392, 1.5800305699286084, 1.6010962313962682, 1.6118760939515901, 1.5971602224018513, 1.5997496608006978, 1.5947782082268307, 1.626647358399027], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.082907027001056, 'batch_acquisition_elapsed_time': 261.0707146880013, 'prior_pool_entropy': 0.7959083890413442, 'batch_pool_mi': 0.47236695913904075})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8871, 'nll': 0.4599343884661743, 'entropy': 0.6861170187226796}, 'active_entropy': 0.6455774782847988, 'chosen_targets': [3, 0, 9, 0, 6, 4, 0, 3, 5, 3], 'chosen_samples': [1756, 34508, 27430, 49354, 32994, 40793, 13030, 54191, 54671, 3051], 'chosen_samples_score': [1.0584374531522034, 1.128064964567019, 1.5100507466387594, 1.590322884213463, 1.6039947394959317, 1.6070271791802953, 1.6031723257890995, 1.6147727994933838, 1.6114980705445383, 1.6157023637322698], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.001492685001722, 'batch_acquisition_elapsed_time': 257.4093976990007, 'prior_pool_entropy': 0.7533901366523262, 'batch_pool_mi': 0.4463770370744377})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8683, 'nll': 0.4875102720012837, 'entropy': 0.7059976141661426}, 'active_entropy': 0.7108534165685354, 'chosen_targets': [6, 9, 5, 0, 9, 7, 0, 5, 5, 0], 'chosen_samples': [1224, 58850, 2571, 16326, 17501, 24984, 55556, 21204, 28951, 53038], 'chosen_samples_score': [1.2362022071049998, 1.2409460630772482, 1.5453610819085426, 1.5994389933140922, 1.6075832847597171, 1.626391394964114, 1.6073456000987232, 1.6191035837517385, 1.6155104983247721, 1.5972993072686443], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.0786429309991945, 'batch_acquisition_elapsed_time': 256.7653234110003, 'prior_pool_entropy': 0.734261965671553, 'batch_pool_mi': 0.4441588619381928})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.883, 'nll': 0.4662789956791887, 'entropy': 0.7753583923393872}, 'active_entropy': 0.5458936624094762, 'chosen_targets': [8, 3, 2, 5, 5, 2, 2, 5, 5, 4], 'chosen_samples': [333, 6920, 12254, 51492, 26150, 28920, 863, 39208, 21626, 43906], 'chosen_samples_score': [0.9537145546751016, 1.0132914833009554, 1.4684477099248847, 1.57890165027288, 1.599322322539392, 1.6114753301141977, 1.604745619014193, 1.6063349361264283, 1.6070022837675846, 1.6249885383290064], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.052905795000697, 'batch_acquisition_elapsed_time': 256.43561158300145, 'prior_pool_entropy': 0.677491832190622, 'batch_pool_mi': 0.316857761076146})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8708, 'nll': 0.5075266757573434, 'entropy': 0.7019730566844464}, 'active_entropy': 0.792733719333774, 'chosen_targets': [5, 6, 9, 4, 9, 1, 0, 9, 4, 1], 'chosen_samples': [610, 1642, 16628, 10918, 5320, 27250, 51464, 56021, 57972, 17129], 'chosen_samples_score': [0.837745921263587, 1.2362141912091542, 1.539041065115517, 1.5904815068139895, 1.6040518610737116, 1.6081058169729454, 1.611385098864174, 1.6111306609793457, 1.6211479192387919, 1.6056137111559199], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.0051089900007355, 'batch_acquisition_elapsed_time': 256.6471535410019, 'prior_pool_entropy': 0.74953560590781, 'batch_pool_mi': 0.4242655186555069})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9046, 'nll': 0.40428101464993244, 'entropy': 0.720499078198053}, 'active_entropy': 0.5191832432843677, 'chosen_targets': [9, 9, 2, 3, 2, 6, 2, 9, 7, 5], 'chosen_samples': [87, 12903, 13654, 34536, 49192, 15386, 27537, 19824, 17776, 16011], 'chosen_samples_score': [0.9325026133083857, 1.1845791971270017, 1.5007064423169454, 1.5775034529160603, 1.5981268206216526, 1.618524588039746, 1.6023552370662268, 1.6184922931677534, 1.6057624578066365, 1.6185720295805877], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 4.982579455998348, 'batch_acquisition_elapsed_time': 256.29742397500013, 'prior_pool_entropy': 0.6178985292141533, 'batch_pool_mi': 0.32377104117619154})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8999, 'nll': 0.4105432055283852, 'entropy': 0.7127324950421269}, 'active_entropy': 0.7677557938668109, 'chosen_targets': [4, 2, 7, 0, 8, 5, 3, 3, 2, 2], 'chosen_samples': [1149, 56175, 33057, 28840, 3026, 32323, 13488, 43256, 16327, 26613], 'chosen_samples_score': [0.9270518080353513, 1.2422665928485075, 1.508554478553018, 1.5754660857121947, 1.5992945631937228, 1.6115124443788162, 1.61381776308462, 1.5979444194265815, 1.594775767916404, 1.5997414449415532], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 4.991763449997961, 'batch_acquisition_elapsed_time': 256.4296751540023, 'prior_pool_entropy': 0.8201387718961101, 'batch_pool_mi': 0.4905750032676482})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9012, 'nll': 0.4524337006927031, 'entropy': 0.814613871401952}, 'active_entropy': 0.7998145076514311, 'chosen_targets': [1, 5, 2, 5, 5, 3, 5, 2, 6, 7], 'chosen_samples': [345, 43638, 54756, 16533, 55513, 34660, 1162, 28, 3524, 3140], 'chosen_samples_score': [0.8029693322927987, 1.1635751606429519, 1.4586458097640116, 1.5560908721472861, 1.5923213060006072, 1.607666733267635, 1.6170882624508964, 1.6190593578953756, 1.6135502720093653, 1.5766475386257932], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.119611107998935, 'batch_acquisition_elapsed_time': 256.6052481259976, 'prior_pool_entropy': 0.8680366058340847, 'batch_pool_mi': 0.5902504688757976})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9112, 'nll': 0.3957008007034222, 'entropy': 0.7461104585043349}, 'active_entropy': 0.7107482542367007, 'chosen_targets': [0, 9, 5, 2, 5, 9, 5, 5, 4, 8], 'chosen_samples': [1168, 5740, 31926, 40614, 54928, 6238, 16356, 54577, 25014, 46864], 'chosen_samples_score': [0.8172985679974047, 1.1262828796659896, 1.4807341497675155, 1.5713938930630675, 1.5982485493623146, 1.6081216609377962, 1.6158041336412237, 1.6011673810818046, 1.5950969382667122, 1.6155109685785707], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.019821054000204, 'batch_acquisition_elapsed_time': 256.8865664629993, 'prior_pool_entropy': 0.7322317120616285, 'batch_pool_mi': 0.46684313005066436})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9053, 'nll': 0.4058959423817899, 'entropy': 0.7365568377961882}, 'active_entropy': 0.7760895573520435, 'chosen_targets': [2, 2, 3, 9, 5, 9, 5, 9, 5, 8], 'chosen_samples': [1662, 30884, 11979, 59344, 6324, 5044, 31301, 9673, 47528, 32166], 'chosen_samples_score': [1.1002683801262803, 1.2722663091746749, 1.5280859722147802, 1.586172557917708, 1.6009504515648123, 1.6168374438280395, 1.619729872495971, 1.6216238289796374, 1.616817664091859, 1.6279810647372965], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.001654577001318, 'batch_acquisition_elapsed_time': 255.77189302100305, 'prior_pool_entropy': 0.9344449121837602, 'batch_pool_mi': 0.5216688029513223})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8756, 'nll': 0.5013865491106387, 'entropy': 0.8879458004428061}, 'active_entropy': 0.5522512299032686, 'chosen_targets': [6, 6, 3, 6, 6, 7, 8, 0, 2, 6], 'chosen_samples': [2096, 11038, 41653, 20057, 34578, 9588, 935, 46412, 6633, 16766], 'chosen_samples_score': [0.7841476586726964, 1.1775491224784687, 1.498582513740777, 1.5800098614977869, 1.5983951355839041, 1.6106706317182171, 1.6157167645169466, 1.6029470340683902, 1.6104900927869057, 1.6132674553925623], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.0241945599991595, 'batch_acquisition_elapsed_time': 256.7722228599996, 'prior_pool_entropy': 0.7027556606972829, 'batch_pool_mi': 0.392636949760862})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9047, 'nll': 0.4512314974891344, 'entropy': 0.8689132400111205}, 'active_entropy': 0.6872719967561277, 'chosen_targets': [4, 9, 2, 5, 7, 2, 8, 8, 7, 5], 'chosen_samples': [164, 37318, 42503, 52106, 28930, 15434, 34328, 14896, 29450, 52086], 'chosen_samples_score': [0.7882109089063534, 0.9820337102630434, 1.432613571089064, 1.5460479049772438, 1.587168582044844, 1.6081045831983656, 1.5935244305506315, 1.593820774633354, 1.6065164816789395, 1.5901125246827883], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.118219272997521, 'batch_acquisition_elapsed_time': 256.05406676200073, 'prior_pool_entropy': 0.8362715249179242, 'batch_pool_mi': 0.4119794925738214})
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'batch_size': 64, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 30, 'epoch_samples': 5056, 'quickquick': False, 'balanced_validation_set': False, 'num_inference_samples': 5, 'no_cuda': False, 'name': 'results', 'seed': 1, 'train_dataset_limit': 0, 'balanced_training_set': False, 'balanced_test_set': False, 'log_interval': 10, 'dataset': 'DatasetEnum.mnist'}
store = {}
store['args']={'batch_size': 64, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 30, 'epoch_samples': 5056, 'quickquick': False, 'balanced_validation_set': False, 'num_inference_samples': 5, 'no_cuda': False, 'name': 'results', 'seed': 1, 'train_dataset_limit': 0, 'balanced_training_set': False, 'balanced_test_set': False, 'log_interval': 10, 'dataset': 'DatasetEnum.mnist'}
store['validations']=[]
store['losses']=[]
store['losses'].append(2.384845733642578)
store['losses'].append(2.3120625019073486)
store['losses'].append(2.231938123703003)
store['losses'].append(2.280470609664917)
store['losses'].append(2.299128532409668)
store['losses'].append(2.156297206878662)
store['losses'].append(2.0693321228027344)
store['losses'].append(2.013458490371704)
store['losses'].append(1.9508134126663208)
store['losses'].append(1.8195449113845825)
store['losses'].append(1.9198130369186401)
store['losses'].append(1.6965878009796143)
store['losses'].append(1.617599368095398)
store['losses'].append(1.517932653427124)
store['losses'].append(1.5855991840362549)
store['losses'].append(1.2787249088287354)
store['losses'].append(1.081629753112793)
store['losses'].append(1.06541109085083)
store['losses'].append(0.9399585723876953)
store['losses'].append(0.9462317228317261)
store['losses'].append(1.0910691022872925)
store['losses'].append(0.8689134120941162)
store['losses'].append(0.855390727519989)
store['losses'].append(0.9781849384307861)
store['losses'].append(0.8307483196258545)
store['losses'].append(0.9400872588157654)
store['losses'].append(0.8373001217842102)
store['losses'].append(0.6574848890304565)
store['losses'].append(0.9949904680252075)
store['losses'].append(0.5952301621437073)
store['losses'].append(0.4628738462924957)
store['losses'].append(0.778171181678772)
store['losses'].append(0.5033957362174988)
store['losses'].append(0.8102746605873108)
store['losses'].append(0.508837103843689)
store['losses'].append(0.7846095561981201)
store['losses'].append(0.5056198239326477)
store['losses'].append(0.7234387397766113)
store['losses'].append(0.44986391067504883)
store['losses'].append(0.5291469097137451)
store['losses'].append(0.3756334185600281)
store['losses'].append(1.033678412437439)
store['losses'].append(0.4241909980773926)
store['losses'].append(0.6142071485519409)
store['losses'].append(0.4116070568561554)
store['losses'].append(0.47126391530036926)
store['losses'].append(0.6934494376182556)
store['losses'].append(0.712856113910675)
store['losses'].append(0.6387879252433777)
store['losses'].append(0.4813013970851898)
store['losses'].append(0.3780968189239502)
store['losses'].append(0.3940877914428711)
store['losses'].append(0.3638020157814026)
store['losses'].append(0.6402643322944641)
store['losses'].append(0.316000759601593)
store['losses'].append(0.4280101954936981)
store['losses'].append(0.5282794833183289)
store['losses'].append(0.7391468286514282)
store['losses'].append(0.48362088203430176)
store['losses'].append(0.6185457706451416)
store['losses'].append(0.5772101283073425)
store['losses'].append(0.47909796237945557)
store['losses'].append(0.22659079730510712)
store['losses'].append(0.23400278389453888)
store['losses'].append(0.40128713846206665)
store['losses'].append(0.5752506256103516)
store['losses'].append(0.42683643102645874)
store['losses'].append(0.4518142342567444)
store['losses'].append(0.3778253197669983)
store['losses'].append(0.3271150588989258)
store['losses'].append(0.22230565547943115)
store['losses'].append(0.5502893924713135)
store['losses'].append(0.4797719717025757)
store['losses'].append(0.653301477432251)
store['losses'].append(0.2571854591369629)
store['losses'].append(0.5111874938011169)
store['losses'].append(0.37221023440361023)
store['losses'].append(0.2752128541469574)
store['losses'].append(0.4593188464641571)
store['losses'].append(0.3906196653842926)
store['losses'].append(0.4631749987602234)
store['losses'].append(0.40646809339523315)
store['losses'].append(0.5870429277420044)
store['losses'].append(0.380068302154541)
store['losses'].append(0.4218604862689972)
store['losses'].append(0.6019142270088196)
store['losses'].append(0.3275855481624603)
store['losses'].append(0.36371704936027527)
store['losses'].append(0.3036210834980011)
store['losses'].append(0.2141517847776413)
store['losses'].append(0.6537988185882568)
store['losses'].append(0.40349066257476807)
store['losses'].append(0.2525547742843628)
store['losses'].append(0.612658679485321)
store['losses'].append(0.3970077931880951)
store['losses'].append(0.47042742371559143)
store['losses'].append(0.34849029779434204)
store['losses'].append(0.3127974271774292)
store['losses'].append(0.24765519797801971)
store['losses'].append(0.4031979441642761)
store['losses'].append(0.20532891154289246)
store['losses'].append(0.36077916622161865)
store['losses'].append(0.13813075423240662)
store['losses'].append(0.30644339323043823)
store['losses'].append(0.3031057119369507)
store['losses'].append(0.2665579915046692)
store['losses'].append(0.49799811840057373)
store['losses'].append(0.2690052390098572)
store['losses'].append(0.20803137123584747)
store['losses'].append(0.1529359668493271)
store['losses'].append(0.5829335451126099)
store['losses'].append(0.237042635679245)
store['losses'].append(0.31020450592041016)
store['losses'].append(0.2739092707633972)
store['losses'].append(0.2793760597705841)
store['losses'].append(0.2563074231147766)
store['losses'].append(0.24654899537563324)
store['losses'].append(0.34352290630340576)
store['losses'].append(0.3166763484477997)
store['losses'].append(0.23830266296863556)
store['losses'].append(0.37966641783714294)
store['losses'].append(0.4115504026412964)
store['losses'].append(0.48746079206466675)
store['losses'].append(0.27073410153388977)
store['losses'].append(0.24906374514102936)
store['losses'].append(0.13313014805316925)
store['losses'].append(0.2732105851173401)
store['losses'].append(0.2513294816017151)
store['losses'].append(0.20605675876140594)
store['losses'].append(0.2843264937400818)
store['losses'].append(0.3189648985862732)
store['losses'].append(0.2683044970035553)
store['losses'].append(0.3174530267715454)
store['losses'].append(0.2284463346004486)
store['losses'].append(0.21445304155349731)
store['losses'].append(0.7104095220565796)
store['losses'].append(0.16889925301074982)
store['losses'].append(0.3182813823223114)
store['losses'].append(0.23135247826576233)
store['losses'].append(0.36997830867767334)
store['losses'].append(0.1841939091682434)
store['losses'].append(0.1887078434228897)
store['losses'].append(0.15424993634223938)
store['losses'].append(0.28981858491897583)
store['losses'].append(0.15532280504703522)
store['losses'].append(0.42086097598075867)
store['losses'].append(0.3824160397052765)
store['losses'].append(0.30451324582099915)
store['losses'].append(0.3482246994972229)
store['losses'].append(0.37060725688934326)
store['losses'].append(0.2749706208705902)
store['losses'].append(0.1936350166797638)
store['losses'].append(0.16365116834640503)
store['losses'].append(0.3767078220844269)
store['losses'].append(0.20316806435585022)
store['losses'].append(0.3567543029785156)
store['losses'].append(0.3020203411579132)
store['losses'].append(0.2972642779350281)
store['losses'].append(0.2779911458492279)
store['losses'].append(0.37161004543304443)
store['losses'].append(0.40835878252983093)
store['losses'].append(0.2216906100511551)
store['losses'].append(0.1666504144668579)
store['losses'].append(0.22818297147750854)
store['losses'].append(0.472370445728302)
store['losses'].append(0.20663335919380188)
store['losses'].append(0.4148707389831543)
store['losses'].append(0.6653959155082703)
store['losses'].append(0.18805278837680817)
store['losses'].append(0.310508668422699)
store['losses'].append(0.3872981667518616)
store['losses'].append(0.2898367643356323)
store['losses'].append(0.20485685765743256)
store['losses'].append(0.19704334437847137)
store['losses'].append(0.22680392861366272)
store['losses'].append(0.23288290202617645)
store['losses'].append(0.3612760305404663)
store['losses'].append(0.2138315886259079)
store['losses'].append(0.3454357087612152)
store['losses'].append(0.12505553662776947)
store['losses'].append(0.2570803761482239)
store['losses'].append(0.2573395371437073)
store['losses'].append(0.1916952282190323)
store['losses'].append(0.3984965682029724)
store['losses'].append(0.23332199454307556)
store['losses'].append(0.14032651484012604)
store['losses'].append(0.1675472855567932)
store['losses'].append(0.13859103620052338)
store['losses'].append(0.15617087483406067)
store['losses'].append(0.25960245728492737)
store['losses'].append(0.32530805468559265)
store['losses'].append(0.10228539258241653)
store['losses'].append(0.31364941596984863)
store['losses'].append(0.3614475727081299)
store['losses'].append(0.2255517542362213)
store['losses'].append(0.22648964822292328)
store['losses'].append(0.343042254447937)
store['losses'].append(0.2500046193599701)
store['losses'].append(0.1536622941493988)
store['losses'].append(0.24845531582832336)
store['losses'].append(0.24628546833992004)
store['losses'].append(0.29009783267974854)
store['losses'].append(0.2942827641963959)
store['losses'].append(0.11765879392623901)
store['losses'].append(0.337610125541687)
store['losses'].append(0.05899754539132118)
store['losses'].append(0.14849677681922913)
store['losses'].append(0.19736549258232117)
store['losses'].append(0.16188396513462067)
store['losses'].append(0.26598188281059265)
store['losses'].append(0.4595280587673187)
store['losses'].append(0.14021502435207367)
store['losses'].append(0.21709378063678741)
store['losses'].append(0.23188471794128418)
store['losses'].append(0.275888592004776)
store['losses'].append(0.27351850271224976)
store['losses'].append(0.34141096472740173)
store['losses'].append(0.22312968969345093)
store['losses'].append(0.3238670229911804)
store['losses'].append(0.20758220553398132)
store['losses'].append(0.2035302370786667)
store['losses'].append(0.11494014412164688)
store['losses'].append(0.10148075968027115)
store['losses'].append(0.19494502246379852)
store['losses'].append(0.08388519287109375)
store['losses'].append(0.13549034297466278)
store['losses'].append(0.16362622380256653)
store['losses'].append(0.2628684639930725)
store['losses'].append(0.3005129396915436)
store['losses'].append(0.10617385059595108)
store['losses'].append(0.19468705356121063)
store['losses'].append(0.28537848591804504)
store['losses'].append(0.20224609971046448)
store['losses'].append(0.24766433238983154)
store['losses'].append(0.21980202198028564)
store['losses'].append(0.19890600442886353)
store['losses'].append(0.21832042932510376)
store['losses'].append(0.21930138766765594)
store['losses'].append(0.07018852233886719)
store['losses'].append(0.29140612483024597)
store['losses'].append(0.27262723445892334)
store['losses'].append(0.19815683364868164)
store['losses'].append(0.2784995138645172)
store['losses'].append(0.19665183126926422)
store['losses'].append(0.10922431200742722)
store['losses'].append(0.11566966027021408)
store['losses'].append(0.19177478551864624)
store['losses'].append(0.2221502810716629)
store['losses'].append(0.14226314425468445)
store['losses'].append(0.188210591673851)
store['losses'].append(0.3000412881374359)
store['losses'].append(0.2657829523086548)
store['losses'].append(0.31485873460769653)
store['losses'].append(0.34386515617370605)
store['losses'].append(0.26993614435195923)
store['losses'].append(0.4124596416950226)
store['losses'].append(0.32578617334365845)
store['losses'].append(0.055211275815963745)
store['losses'].append(0.25675782561302185)
store['losses'].append(0.3729792535305023)
store['losses'].append(0.11761318892240524)
store['losses'].append(0.12223055958747864)
store['losses'].append(0.23232316970825195)
store['losses'].append(0.24249735474586487)
store['losses'].append(0.2611423134803772)
store['losses'].append(0.13724187016487122)
store['losses'].append(0.3490976095199585)
store['losses'].append(0.16951988637447357)
store['losses'].append(0.17741228640079498)
store['losses'].append(0.12501752376556396)
store['losses'].append(0.1247333288192749)
store['losses'].append(0.376277893781662)
store['losses'].append(0.4053453505039215)
store['losses'].append(0.2797052562236786)
store['losses'].append(0.11528559029102325)
store['losses'].append(0.20614445209503174)
store['losses'].append(0.2596794366836548)
store['losses'].append(0.2632741630077362)
store['losses'].append(0.2036980390548706)
store['losses'].append(0.30314621329307556)
store['losses'].append(0.186393603682518)
store['losses'].append(0.12207289040088654)
store['losses'].append(0.10781947523355484)
store['losses'].append(0.1761208176612854)
store['losses'].append(0.15027271211147308)
store['losses'].append(0.32289278507232666)
store['losses'].append(0.23054030537605286)
store['losses'].append(0.3418934643268585)
store['losses'].append(0.2988121509552002)
store['losses'].append(0.1435302346944809)
store['losses'].append(0.4765307307243347)
store['losses'].append(0.18480417132377625)
store['losses'].append(0.36758744716644287)
store['losses'].append(0.2499811202287674)
store['losses'].append(0.16513609886169434)
store['losses'].append(0.11862245947122574)
store['losses'].append(0.25034743547439575)
store['losses'].append(0.21328520774841309)
store['losses'].append(0.08830475807189941)
store['losses'].append(0.29150310158729553)
store['losses'].append(0.16348959505558014)
store['losses'].append(0.22526392340660095)
store['losses'].append(0.17079849541187286)
store['losses'].append(0.12268687784671783)
store['losses'].append(0.2608101963996887)
store['losses'].append(0.15682187676429749)
store['losses'].append(0.1501167118549347)
store['losses'].append(0.0316496267914772)
store['losses'].append(0.16870249807834625)
store['losses'].append(0.10365287214517593)
store['losses'].append(0.1628757268190384)
store['losses'].append(0.18083980679512024)
store['losses'].append(0.2181934416294098)
store['losses'].append(0.3369835913181305)
store['losses'].append(0.23508864641189575)
store['losses'].append(0.1489512324333191)
store['losses'].append(0.12236230820417404)
store['losses'].append(0.1789223551750183)
store['losses'].append(0.16027598083019257)
store['losses'].append(0.15523594617843628)
store['losses'].append(0.09774484485387802)
store['losses'].append(0.16578075289726257)
store['losses'].append(0.3230147659778595)
store['losses'].append(0.19721344113349915)
store['losses'].append(0.21258710324764252)
store['losses'].append(0.04941525682806969)
store['losses'].append(0.3046320080757141)
store['losses'].append(0.07419171184301376)
store['losses'].append(0.18815793097019196)
store['losses'].append(0.26572662591934204)
store['losses'].append(0.2182530164718628)
store['losses'].append(0.109939806163311)
store['losses'].append(0.16114717721939087)
store['losses'].append(0.5539407134056091)
store['losses'].append(0.11034049838781357)
store['losses'].append(0.26972267031669617)
store['losses'].append(0.19940350949764252)
store['losses'].append(0.10794764012098312)
store['losses'].append(0.06077481433749199)
store['losses'].append(0.16398681700229645)
store['losses'].append(0.11070399731397629)
store['losses'].append(0.2206435650587082)
store['losses'].append(0.2872823476791382)
store['losses'].append(0.46515005826950073)
store['losses'].append(0.25641775131225586)
store['losses'].append(0.1652999222278595)
store['losses'].append(0.10066290199756622)
store['losses'].append(0.20538635551929474)
store['losses'].append(0.2193882018327713)
store['losses'].append(0.26428425312042236)
store['losses'].append(0.15914393961429596)
store['losses'].append(0.10128244757652283)
store['losses'].append(0.16479192674160004)
store['losses'].append(0.29805001616477966)
store['losses'].append(0.21949924528598785)
store['losses'].append(0.07505369186401367)
store['losses'].append(0.19157397747039795)
store['losses'].append(0.13861078023910522)
store['losses'].append(0.15437039732933044)
store['losses'].append(0.2537097930908203)
store['losses'].append(0.20994965732097626)
store['losses'].append(0.22034014761447906)
store['losses'].append(0.10781754553318024)
store['losses'].append(0.34921303391456604)
store['losses'].append(0.15364599227905273)
store['losses'].append(0.11380881816148758)
store['losses'].append(0.1537778526544571)
store['losses'].append(0.2895217835903168)
store['losses'].append(0.3807874321937561)
store['losses'].append(0.17721182107925415)
store['losses'].append(0.3921293616294861)
store['losses'].append(0.21609623730182648)
store['losses'].append(0.27795469760894775)
store['losses'].append(0.15430785715579987)
store['losses'].append(0.400490403175354)
store['losses'].append(0.15198031067848206)
store['losses'].append(0.2610144317150116)
store['losses'].append(0.21945491433143616)
store['losses'].append(0.27996546030044556)
store['losses'].append(0.16403043270111084)
store['losses'].append(0.08237219601869583)
store['losses'].append(0.124985471367836)
store['losses'].append(0.07734400779008865)
store['losses'].append(0.24812643229961395)
store['losses'].append(0.4150833487510681)
store['losses'].append(0.17767341434955597)
store['losses'].append(0.1250164657831192)
store['losses'].append(0.15384815633296967)
store['losses'].append(0.2062465250492096)
store['losses'].append(0.15809862315654755)
store['losses'].append(0.08876638859510422)
store['losses'].append(0.19598613679409027)
store['losses'].append(0.1701638251543045)
store['losses'].append(0.2193051129579544)
store['losses'].append(0.17208188772201538)
store['losses'].append(0.458501935005188)
store['losses'].append(0.16368156671524048)
store['losses'].append(0.1649809628725052)
store['losses'].append(0.16490226984024048)
store['losses'].append(0.10117711871862411)
store['losses'].append(0.06380750238895416)
store['losses'].append(0.22725078463554382)
store['losses'].append(0.2660742998123169)
store['losses'].append(0.30417370796203613)
store['losses'].append(0.3526330590248108)
store['losses'].append(0.20793458819389343)
store['losses'].append(0.13053986430168152)
store['losses'].append(0.13955190777778625)
store['losses'].append(0.4004547595977783)
store['losses'].append(0.18254849314689636)
store['losses'].append(0.075607068836689)
store['losses'].append(0.1449548751115799)
store['losses'].append(0.2957085967063904)
store['losses'].append(0.15904363989830017)
store['losses'].append(0.32784101366996765)
store['losses'].append(0.09498490393161774)
store['losses'].append(0.0661434680223465)
store['losses'].append(0.10469437390565872)
store['losses'].append(0.19990237057209015)
store['losses'].append(0.2479001134634018)
store['losses'].append(0.060111235827207565)
store['losses'].append(0.08850602805614471)
store['losses'].append(0.07527731359004974)
store['losses'].append(0.1755458265542984)
store['losses'].append(0.19762396812438965)
store['losses'].append(0.40189850330352783)
store['losses'].append(0.08666155487298965)
store['losses'].append(0.18857723474502563)
store['losses'].append(0.08691409975290298)
store['losses'].append(0.1763986051082611)
store['losses'].append(0.13190151751041412)
store['losses'].append(0.43083682656288147)
store['losses'].append(0.18933264911174774)
store['losses'].append(0.4969499111175537)
store['losses'].append(0.19296856224536896)
store['losses'].append(0.2189406007528305)
store['losses'].append(0.05590946599841118)
store['losses'].append(0.16635975241661072)
store['losses'].append(0.2640509307384491)
store['losses'].append(0.14411447942256927)
store['losses'].append(0.17214733362197876)
store['losses'].append(0.15769274532794952)
store['losses'].append(0.2757687270641327)
store['losses'].append(0.23593156039714813)
store['losses'].append(0.14678075909614563)
store['losses'].append(0.4018417298793793)
store['losses'].append(0.2062792032957077)
store['losses'].append(0.06058051437139511)
store['losses'].append(0.10660306364297867)
store['losses'].append(0.1404586285352707)
store['losses'].append(0.09364603459835052)
store['losses'].append(0.06320368498563766)
store['losses'].append(0.22204378247261047)
store['losses'].append(0.0868096798658371)
store['losses'].append(0.14976458251476288)
store['losses'].append(0.1300387978553772)
store['losses'].append(0.06073036417365074)
store['losses'].append(0.3594387471675873)
store['losses'].append(0.08531444519758224)
store['losses'].append(0.12933099269866943)
store['losses'].append(0.03166574612259865)
store['losses'].append(0.38652050495147705)
store['losses'].append(0.28338906168937683)
store['losses'].append(0.12378229200839996)
store['losses'].append(0.1996353417634964)
store['losses'].append(0.11211556941270828)
store['losses'].append(0.28917670249938965)
store['losses'].append(0.2086907923221588)
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6064, 'nll': 1.962251597034733, 'entropy': 0.6602771732741637}, 'active_entropy': 0.7272226057330982, 'chosen_targets': [1, 2, 2, 2, 2, 2, 8, 3, 9, 7], 'chosen_samples': [978, 58468, 9472, 58441, 13743, 42206, 14679, 48761, 49489, 10716], 'chosen_samples_score': [1.495591251884833, 1.545932465745547, 1.6035614402339502, 1.6087857357334923, 1.609333145131871, 1.6037101351475354, 1.6055153242749836, 1.6220694883694193, 1.6127317766396785, 1.604008774137902], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 8.398536345004686, 'batch_acquisition_elapsed_time': 281.42968564700277, 'prior_pool_entropy': 0.8237524642415152, 'batch_pool_mi': 0.427660010357611})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6437, 'nll': 1.4200249882281764, 'entropy': 0.659999626600777}, 'active_entropy': 0.7586111824374414, 'chosen_targets': [6, 7, 2, 7, 2, 2, 7, 3, 6, 1], 'chosen_samples': [672, 4266, 14125, 27103, 12196, 52959, 3782, 38804, 7867, 42268], 'chosen_samples_score': [1.3152778201720272, 1.5024516941879082, 1.5939599096920851, 1.6077923607261624, 1.609139038002351, 1.5993370212229703, 1.6146217658926556, 1.6097515460991483, 1.5888545341181484, 1.598825269780007], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.532547508002608, 'batch_acquisition_elapsed_time': 280.85144458400464, 'prior_pool_entropy': 0.9258962200628295, 'batch_pool_mi': 0.5721020079010514})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7369, 'nll': 1.0087700132651738, 'entropy': 0.6227847620113118}, 'active_entropy': 0.6679481606897831, 'chosen_targets': [4, 5, 0, 7, 9, 9, 2, 5, 8, 8], 'chosen_samples': [61, 35787, 44598, 33838, 32930, 23863, 17212, 55233, 38065, 2678], 'chosen_samples_score': [1.1225813763900627, 1.5133039731199978, 1.6017450664074036, 1.6084089082709319, 1.6093043685170851, 1.6196043479710074, 1.6119109217633314, 1.5767067888593207, 1.6145615950179781, 1.5934579530045463], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.605455798999174, 'batch_acquisition_elapsed_time': 280.6569425140042, 'prior_pool_entropy': 0.7101342015908564, 'batch_pool_mi': 0.2320947495581892})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8049, 'nll': 0.6500340079814708, 'entropy': 0.6153607320245683}, 'active_entropy': 0.6324418761971887, 'chosen_targets': [6, 8, 7, 8, 0, 3, 7, 8, 5, 7], 'chosen_samples': [1866, 27851, 16379, 21457, 28412, 15857, 10744, 18214, 25622, 50126], 'chosen_samples_score': [1.1592582782875862, 1.4453897460054559, 1.5786937540698414, 1.6052927780671795, 1.6087200957477392, 1.5903691982486912, 1.6115502608451124, 1.6048748910481816, 1.6229774071229266, 1.6065829835788552], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 6.209238040995842, 'batch_acquisition_elapsed_time': 277.38546741200116, 'prior_pool_entropy': 0.6859885328045779, 'batch_pool_mi': 0.363738545222029})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7692, 'nll': 0.7388645637210373, 'entropy': 0.6177481492368443}, 'active_entropy': 0.5980666808428131, 'chosen_targets': [6, 5, 3, 5, 7, 0, 5, 9, 5, 6], 'chosen_samples': [735, 27062, 15250, 6472, 8954, 19369, 36126, 42020, 47471, 47415], 'chosen_samples_score': [1.0695067413239563, 1.352863740987031, 1.563540233421949, 1.6045905439458785, 1.608722684310247, 1.6030309260736277, 1.6210178269545563, 1.625321300180513, 1.612427245987023, 1.6052212235471406], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 6.569256214999768, 'batch_acquisition_elapsed_time': 277.3734021650016, 'prior_pool_entropy': 0.6660182216864701, 'batch_pool_mi': 0.2826608527306416})
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.599, 'nll': 1.6921393426831681, 'entropy': 0.7532242324622124}, 'active_entropy': 0.8636358791987943, 'chosen_targets': [1, 2, 2, 9, 3, 3, 5, 5, 4, 8], 'chosen_samples': [648, 8810, 42327, 29472, 9180, 19280, 1071, 30402, 9597, 17036], 'chosen_samples_score': [1.4783128744798244, 1.5557694874662642, 1.6052222124584898, 1.6090418545816005, 1.6094165966218559, 1.6092852583864539, 1.6188426013258794, 1.6148996496363472, 1.6058025099699487, 1.6199619515021935], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 7.355023179001364, 'batch_acquisition_elapsed_time': 279.1585306019988, 'prior_pool_entropy': 0.9055479024566877, 'batch_pool_mi': 0.5223053573106642})
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.ical', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6012, 'nll': 1.8179996444613205, 'entropy': 0.6899427108729821}, 'active_entropy': 0.7044821139155389, 'chosen_targets': [7, 4, 4, 4, 3, 4, 2, 7, 0, 4], 'chosen_samples': [1001, 19121, 47843, 14947, 255, 2071, 56263, 5626, 30699, 14715], 'chosen_samples_score': [1.2758394223699216, 1.5056878567612544, 1.5994146373262828, 1.6080570001071963, 1.60920154208556, 1.6139231401230023, 1.6192318394541299, 1.6156778121895714, 1.60786755817149, 1.611733124859053], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 8.541494034005154, 'batch_acquisition_elapsed_time': 291.2082196129995, 'prior_pool_entropy': 0.8039671309208365, 'batch_pool_mi': 0.3725637207371258})
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6042, 'nll': 1.8671361429017521, 'entropy': 0.7050638376324339}, 'active_entropy': 0.7336280762716598, 'chosen_targets': [4, 7, 0, 2, 8, 7, 6, 0, 2, 9], 'chosen_samples': [2360, 50440, 26923, 42327, 37783, 23526, 15188, 8273, 39097, 30277], 'chosen_samples_score': [1.2476416952343807, 1.5496759109124132, 1.6034084732722016, 1.6087598099793465, 1.6093657162079598, 1.6152881554369205, 1.6075673427815145, 1.6076587706640626, 1.6110848296273628, 1.61044415282276], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 8.447840405999159, 'batch_acquisition_elapsed_time': 282.8638065999985, 'prior_pool_entropy': 0.7734581982287347, 'batch_pool_mi': 0.3465022850222106})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.6447, 'nll': 1.5720433990184286, 'entropy': 0.6394292612703639}, 'active_entropy': 0.57994879876219, 'chosen_targets': [3, 4, 7, 9, 9, 2, 2, 3, 3, 7], 'chosen_samples': [1234, 16875, 23946, 8702, 14015, 34252, 16473, 4792, 6293, 58530], 'chosen_samples_score': [1.1044619324349498, 1.4196775497801557, 1.5754812685445412, 1.6011750338245554, 1.6076322196692383, 1.6114950856968966, 1.6134677264210773, 1.6054458529258806, 1.6014041286276193, 1.6101826965028985], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.274200749998272, 'batch_acquisition_elapsed_time': 271.72858704600367, 'prior_pool_entropy': 0.6525536137442219, 'batch_pool_mi': 0.2795746428715777})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7368, 'nll': 1.0058776791307407, 'entropy': 0.625176564500033}, 'active_entropy': 0.6284453577819863, 'chosen_targets': [3, 1, 5, 1, 5, 1, 1, 1, 8, 4], 'chosen_samples': [546, 48793, 19959, 24447, 19973, 25485, 49395, 11630, 7051, 12760], 'chosen_samples_score': [1.2362673391740873, 1.5107227787836137, 1.5970849058562684, 1.6086812127062884, 1.609327969301289, 1.6091214067179629, 1.6091274516420122, 1.598678150954684, 1.6065347966044041, 1.6089405536736083], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.410206594999181, 'batch_acquisition_elapsed_time': 274.7310891840025, 'prior_pool_entropy': 0.7441404108458132, 'batch_pool_mi': 0.35636152344193706})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.7342, 'nll': 1.0190761575898866, 'entropy': 0.5939322767166334}, 'active_entropy': 0.6861918153209621, 'chosen_targets': [3, 8, 4, 5, 4, 6, 7, 4, 8, 0], 'chosen_samples': [953, 41495, 48970, 15571, 3072, 41261, 54212, 3110, 24926, 33378], 'chosen_samples_score': [1.2958666681867188, 1.5280019169310468, 1.6045682503027279, 1.6090421179174852, 1.6093840671886357, 1.6064828927713544, 1.60706049038299, 1.6021449104867407, 1.624517642613787, 1.6069867531039126], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.351548931997968, 'batch_acquisition_elapsed_time': 270.1633805720048, 'prior_pool_entropy': 0.8020050491995764, 'batch_pool_mi': 0.35352686961625807})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8124, 'nll': 0.6806030412244706, 'entropy': 0.5090085916515041}, 'active_entropy': 0.45650766352518973, 'chosen_targets': [7, 7, 2, 7, 2, 4, 2, 4, 0, 6], 'chosen_samples': [868, 39316, 57726, 7033, 36127, 42099, 54240, 32838, 30149, 19896], 'chosen_samples_score': [1.2210938807167082, 1.3606266915307725, 1.6008682966101797, 1.6090340506309848, 1.6094172550569392, 1.6093218840023331, 1.6033496824608635, 1.6132366746440994, 1.61241470259453, 1.6121911636147326], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.440304267998727, 'batch_acquisition_elapsed_time': 270.1683682820003, 'prior_pool_entropy': 0.5860706946245844, 'batch_pool_mi': 0.2306465322931922})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8243, 'nll': 0.6290688968657678, 'entropy': 0.5294345059165882}, 'active_entropy': 0.4186069384697593, 'chosen_targets': [7, 5, 5, 5, 5, 5, 0, 3, 5, 5], 'chosen_samples': [1023, 41737, 21058, 13783, 12650, 11631, 57154, 10360, 43805, 43368], 'chosen_samples_score': [1.2213424219486846, 1.4920447333302655, 1.5972478895401854, 1.6081671045197523, 1.6092785720984317, 1.6173535642969394, 1.6166963218338217, 1.6154805146789153, 1.605886170463001, 1.6111826816084083], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.205879449000349, 'batch_acquisition_elapsed_time': 275.3434784420024, 'prior_pool_entropy': 0.46329114219090706, 'batch_pool_mi': 0.1937948276371988})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8258, 'nll': 0.6021062548073931, 'entropy': 0.5553962717133494}, 'active_entropy': 0.4487053757271066, 'chosen_targets': [8, 5, 2, 8, 5, 3, 1, 2, 2, 5], 'chosen_samples': [925, 15893, 46556, 24589, 14623, 6420, 36908, 5438, 56643, 35287], 'chosen_samples_score': [1.231604202604053, 1.2939139158367625, 1.5622368208398383, 1.6056714690655358, 1.6089824787923406, 1.5994904757802426, 1.617867876667812, 1.598610456260643, 1.6032620225460326, 1.5936649271303835], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.360528613993665, 'batch_acquisition_elapsed_time': 275.6168838570011, 'prior_pool_entropy': 0.5148085393089024, 'batch_pool_mi': 0.18863269867731264})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8257, 'nll': 0.621325115688151, 'entropy': 0.583023859683098}, 'active_entropy': 0.4149673790048849, 'chosen_targets': [5, 8, 8, 3, 7, 1, 8, 5, 5, 0], 'chosen_samples': [1847, 55606, 50459, 7192, 44865, 30238, 24657, 6471, 32511, 51680], 'chosen_samples_score': [0.9742167977249361, 1.1380262097551326, 1.512463883551559, 1.5869578184069972, 1.604038446927989, 1.5951968753797239, 1.6247640743527736, 1.6038854426598088, 1.6132402362987524, 1.5902603422907813], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.405495167004119, 'batch_acquisition_elapsed_time': 274.34653729399724, 'prior_pool_entropy': 0.6051449639482046, 'batch_pool_mi': 0.26729048039202263})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8532, 'nll': 0.4896309842125713, 'entropy': 0.5350602283465228}, 'active_entropy': 0.5268789625006084, 'chosen_targets': [3, 8, 3, 8, 2, 3, 2, 3, 3, 4], 'chosen_samples': [235, 42878, 11545, 42467, 49285, 18397, 12906, 21390, 11693, 32865], 'chosen_samples_score': [1.0321306056959108, 1.313159004184241, 1.5431072236563752, 1.5891647884107725, 1.6030822982475272, 1.6113379972593413, 1.6071204021023178, 1.6030044897644737, 1.6305648064170732, 1.6143478850466693], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.472769357002107, 'batch_acquisition_elapsed_time': 275.4725892380011, 'prior_pool_entropy': 0.5344635282776139, 'batch_pool_mi': 0.30928200129447614})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8724, 'nll': 0.46962032874675297, 'entropy': 0.6272164449617385}, 'active_entropy': 0.7886827424360872, 'chosen_targets': [4, 4, 9, 5, 1, 9, 9, 5, 1, 4], 'chosen_samples': [92, 18473, 41962, 19942, 41744, 22041, 1612, 54914, 10982, 51309], 'chosen_samples_score': [0.9475901132807751, 1.1516262141216873, 1.5162022370480521, 1.5884343882403895, 1.6061387497273927, 1.6165069517412545, 1.606159703501472, 1.583920524661726, 1.61524764673333, 1.6087431106314516], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.42393910499959, 'batch_acquisition_elapsed_time': 275.67282676600007, 'prior_pool_entropy': 0.873916387100327, 'batch_pool_mi': 0.5124167543677873})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8526, 'nll': 0.4865465024956481, 'entropy': 0.5357334543992586}, 'active_entropy': 0.47737336381391665, 'chosen_targets': [5, 8, 3, 0, 6, 5, 3, 3, 3, 6], 'chosen_samples': [690, 39308, 21946, 41811, 54788, 45250, 55190, 17777, 46834, 42405], 'chosen_samples_score': [0.9493550444757788, 1.2861825279281587, 1.5313537052445958, 1.5933549321928995, 1.6047385640145426, 1.6033213003153142, 1.608484477587948, 1.6057258035140571, 1.608991282200483, 1.6128004457275855], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.320362017999287, 'batch_acquisition_elapsed_time': 275.13986871900124, 'prior_pool_entropy': 0.5921226053776852, 'batch_pool_mi': 0.2304829535090314})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8905, 'nll': 0.40472470208543504, 'entropy': 0.5809705097626383}, 'active_entropy': 0.356612497242536, 'chosen_targets': [2, 1, 0, 2, 2, 2, 6, 8, 7, 3], 'chosen_samples': [1800, 5630, 40456, 4986, 37403, 57506, 27101, 16860, 56472, 38772], 'chosen_samples_score': [1.082788732555029, 1.2873582068123166, 1.5667366596913836, 1.603869071081267, 1.6082090415056505, 1.6110977972058649, 1.6207958118773371, 1.594098205858871, 1.609187565538834, 1.623872342445674], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.368059394000738, 'batch_acquisition_elapsed_time': 273.98626399499335, 'prior_pool_entropy': 0.5400623974099551, 'batch_pool_mi': 0.2885836803243473})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8902, 'nll': 0.4081728494873514, 'entropy': 0.5979343277555609}, 'active_entropy': 0.6381594762205959, 'chosen_targets': [2, 0, 2, 8, 8, 8, 3, 0, 2, 8], 'chosen_samples': [2017, 11639, 49567, 57355, 13477, 27293, 43208, 41999, 52169, 41046], 'chosen_samples_score': [0.9329464890865341, 1.1681799217851663, 1.534325432364669, 1.5887830324257701, 1.6037869803503075, 1.6089574412737564, 1.5939259937324808, 1.603378208732634, 1.6134724321486513, 1.6147887443283944], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.617765557995881, 'batch_acquisition_elapsed_time': 275.77111227800197, 'prior_pool_entropy': 0.6540745137387679, 'batch_pool_mi': 0.39247039460425714})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8698, 'nll': 0.43068139861664, 'entropy': 0.6100443848161655}, 'active_entropy': 0.6750732606496572, 'chosen_targets': [4, 8, 4, 4, 2, 4, 2, 4, 5, 4], 'chosen_samples': [754, 35232, 27738, 56244, 48550, 7919, 34902, 52838, 12470, 10918], 'chosen_samples_score': [0.9785607522123899, 1.2205936235688761, 1.512688369717878, 1.5838840009086481, 1.6006577658688927, 1.6232951523405603, 1.6012407481974726, 1.5818898473302871, 1.6016159658775617, 1.610967250307878], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.348047874998883, 'batch_acquisition_elapsed_time': 274.28442040099617, 'prior_pool_entropy': 0.6727174065020187, 'batch_pool_mi': 0.4082934375854106})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8595, 'nll': 0.4659188459801116, 'entropy': 0.6710537864181176}, 'active_entropy': 0.6645390208347245, 'chosen_targets': [1, 5, 4, 5, 5, 4, 7, 8, 9, 5], 'chosen_samples': [1003, 36089, 42774, 59747, 21210, 23187, 51363, 30416, 37879, 17645], 'chosen_samples_score': [1.0145136586422878, 1.1686427539316842, 1.530774163721296, 1.5913231948278166, 1.6051876511126935, 1.6087842581225962, 1.6089608471315318, 1.610374390916566, 1.6123253655818677, 1.6304266299116303], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.44197654400341, 'batch_acquisition_elapsed_time': 274.16463688899967, 'prior_pool_entropy': 0.6131004788541555, 'batch_pool_mi': 0.3570815499958923})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8803, 'nll': 0.41642868059126387, 'entropy': 0.6517627826137931}, 'active_entropy': 0.8373009938369084, 'chosen_targets': [0, 0, 7, 6, 0, 5, 2, 3, 6, 6], 'chosen_samples': [1682, 57020, 11534, 48649, 17539, 1806, 2450, 40104, 5600, 44428], 'chosen_samples_score': [0.8246055354527594, 1.2403037929000673, 1.4991032121782164, 1.584132417183969, 1.6016149862390656, 1.6238975323765017, 1.6086040123904137, 1.6191636209359763, 1.6171620652488894, 1.6048243395576147], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.426500982997823, 'batch_acquisition_elapsed_time': 272.8401306279993, 'prior_pool_entropy': 0.8436371987717376, 'batch_pool_mi': 0.5559887959062959})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8989, 'nll': 0.41005482867712545, 'entropy': 0.7007328942555421}, 'active_entropy': 0.5926877423212213, 'chosen_targets': [3, 9, 9, 0, 5, 9, 0, 8, 8, 8], 'chosen_samples': [1677, 50078, 59314, 17725, 16780, 55856, 20392, 15973, 25873, 50625], 'chosen_samples_score': [0.9863066703182876, 1.2404437139709859, 1.539725493762738, 1.5925789816672808, 1.6045554892489164, 1.5958793505327362, 1.5895371394902487, 1.6110863044245876, 1.6015170457986576, 1.6035274294954256], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.4192585769997095, 'batch_acquisition_elapsed_time': 273.3548732659983, 'prior_pool_entropy': 0.6385542106681258, 'batch_pool_mi': 0.34854086734343326})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8992, 'nll': 0.3857915894079176, 'entropy': 0.6629569321023422}, 'active_entropy': 0.6215928353665554, 'chosen_targets': [7, 9, 2, 8, 4, 3, 9, 9, 7, 4], 'chosen_samples': [446, 31456, 48349, 49509, 23435, 27419, 11208, 19322, 56218, 53753], 'chosen_samples_score': [0.7669451401554958, 1.282496871304783, 1.5290939208140442, 1.5902145004363502, 1.6038626274602474, 1.6070705905579046, 1.6025345700172395, 1.6149513518263507, 1.6235440265919001, 1.6135600473366143], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.388475850995746, 'batch_acquisition_elapsed_time': 270.6516822179983, 'prior_pool_entropy': 0.6581295473186042, 'batch_pool_mi': 0.3883449184707485})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8818, 'nll': 0.4589154440389981, 'entropy': 0.7652955999243947}, 'active_entropy': 0.8051485468913943, 'chosen_targets': [1, 2, 8, 1, 3, 8, 8, 2, 0, 1], 'chosen_samples': [1654, 4843, 12663, 29609, 57308, 12936, 42479, 27898, 40457, 30457], 'chosen_samples_score': [0.8676739766689266, 1.1897639759515246, 1.4865220163908623, 1.5760264683333114, 1.6000793489638632, 1.6003840434228822, 1.6101181028278093, 1.5947783065897463, 1.6133875894531782, 1.6171577657193934], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.41106716899958, 'batch_acquisition_elapsed_time': 270.1377459070063, 'prior_pool_entropy': 0.8902217022873795, 'batch_pool_mi': 0.565942601752868})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8849, 'nll': 0.42805833116748265, 'entropy': 0.6956308923579483}, 'active_entropy': 0.6182824261814829, 'chosen_targets': [6, 2, 4, 4, 4, 9, 4, 5, 7, 4], 'chosen_samples': [331, 4153, 32301, 14335, 15432, 1518, 11852, 20784, 9538, 14349], 'chosen_samples_score': [0.777953185958405, 1.2116309231735214, 1.4810515842722287, 1.5701471869927301, 1.5971348497684552, 1.5887482997751423, 1.6002856700594386, 1.6062078031815066, 1.6052632897172021, 1.6300076298539885], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.367498028004775, 'batch_acquisition_elapsed_time': 269.2009024440049, 'prior_pool_entropy': 0.7085951092617209, 'batch_pool_mi': 0.2584634306087606})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9094, 'nll': 0.3883372574499996, 'entropy': 0.719052858513872}, 'active_entropy': 0.8262512498006827, 'chosen_targets': [5, 2, 8, 2, 5, 8, 7, 3, 8, 2], 'chosen_samples': [1670, 37969, 45673, 37989, 39958, 40852, 42415, 25861, 47726, 19505], 'chosen_samples_score': [0.8096019391064961, 1.2474744695923523, 1.503829773412793, 1.5710942092723628, 1.6011853800380975, 1.60244498786663, 1.6128021604892049, 1.6081464541170165, 1.6168765155902451, 1.6141750460087692], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.290006955001445, 'batch_acquisition_elapsed_time': 270.5487991199989, 'prior_pool_entropy': 0.868349306699972, 'batch_pool_mi': 0.45901027929017274})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9054, 'nll': 0.4069721563500816, 'entropy': 0.7174794087921594}, 'active_entropy': 0.687687894346834, 'chosen_targets': [9, 5, 5, 9, 3, 5, 9, 5, 3, 5], 'chosen_samples': [1116, 28375, 23927, 48888, 8228, 56843, 30342, 50006, 57523, 31782], 'chosen_samples_score': [0.8547204539467087, 1.0711367130953184, 1.4646230630402806, 1.5652459295929693, 1.5946113770510888, 1.6185572693383712, 1.6160402840212775, 1.6176027773197879, 1.5820470829518163, 1.6117652954219057], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.722983330997522, 'batch_acquisition_elapsed_time': 274.71615023799677, 'prior_pool_entropy': 0.7315918888517066, 'batch_pool_mi': 0.34930773798099196})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9033, 'nll': 0.40737911191715176, 'entropy': 0.7486563458747196}, 'active_entropy': 0.6492046509752867, 'chosen_targets': [7, 5, 5, 5, 7, 5, 0, 5, 2, 9], 'chosen_samples': [1770, 33222, 55388, 51492, 7438, 17558, 6832, 42337, 41802, 42457], 'chosen_samples_score': [0.9096921196825843, 1.390386535715335, 1.5556044949674537, 1.6010933925877557, 1.607320289580063, 1.6063968304025655, 1.6122881387010137, 1.6190927650132907, 1.592741544908165, 1.6143351245604505], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.317240379001305, 'batch_acquisition_elapsed_time': 266.13770274000126, 'prior_pool_entropy': 0.6162941610966968, 'batch_pool_mi': 0.27986467096441964})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9053, 'nll': 0.4372893468862023, 'entropy': 0.8351988399008169}, 'active_entropy': 0.7209283158579833, 'chosen_targets': [8, 4, 9, 3, 8, 8, 1, 3, 8, 8], 'chosen_samples': [705, 45048, 49656, 23076, 6905, 57392, 7440, 48628, 11239, 49088], 'chosen_samples_score': [0.7527030109026387, 0.9849373468363474, 1.3084663438471258, 1.4721013936385292, 1.5410180899118666, 1.5775227254850126, 1.594538886608948, 1.624457709084865, 1.6197480210001363, 1.6300230069018298], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.438408711001102, 'batch_acquisition_elapsed_time': 263.2157188619967, 'prior_pool_entropy': 0.7178712176627188, 'batch_pool_mi': 0.354827536800921})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8834, 'nll': 0.4788022231044494, 'entropy': 0.8319971176044851}, 'active_entropy': 0.7038122273529008, 'chosen_targets': [6, 5, 0, 0, 7, 6, 3, 5, 0, 8], 'chosen_samples': [1898, 32537, 53116, 46339, 19648, 39320, 34204, 32533, 9435, 20037], 'chosen_samples_score': [0.7564384364700721, 0.9980005957180851, 1.4403550459439962, 1.5452950013387006, 1.59083671739469, 1.6225054847919607, 1.6011692346358277, 1.6204746519872142, 1.5885129864532685, 1.5980563292072816], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.227065605002281, 'batch_acquisition_elapsed_time': 264.407362893995, 'prior_pool_entropy': 0.7728964797425538, 'batch_pool_mi': 0.3887653586441956})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8812, 'nll': 0.5080558622095656, 'entropy': 0.9486192193404848}, 'active_entropy': 0.9507416849315097, 'chosen_targets': [2, 9, 5, 0, 2, 0, 5, 2, 3, 6], 'chosen_samples': [1988, 826, 26240, 15779, 35378, 40208, 35628, 7619, 57172, 2126], 'chosen_samples_score': [0.566370335535302, 0.8793053307350291, 1.2970833218379156, 1.4574163739836217, 1.537593745386106, 1.569919522517698, 1.5996258880975978, 1.6026778687361682, 1.6006618139153348, 1.6205960740029566], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.300491979003709, 'batch_acquisition_elapsed_time': 264.94622576799884, 'prior_pool_entropy': 0.9120934205918543, 'batch_pool_mi': 0.5859510279591565})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8999, 'nll': 0.40725684825574715, 'entropy': 0.7624020128298232}, 'active_entropy': 0.9536552395264886, 'chosen_targets': [0, 8, 9, 2, 5, 2, 8, 6, 8, 5], 'chosen_samples': [1578, 52306, 13998, 2748, 55042, 22139, 24533, 19947, 52483, 26134], 'chosen_samples_score': [0.7838699092144799, 1.1454920079197128, 1.5190105333826165, 1.5860483651839923, 1.6028365977382641, 1.6011444866590399, 1.6035982652024328, 1.6121433191448657, 1.6137918873423782, 1.607756499873946], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.204908382002031, 'batch_acquisition_elapsed_time': 264.3584756199998, 'prior_pool_entropy': 1.0882282782044879, 'batch_pool_mi': 0.8207791620318796})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8872, 'nll': 0.4695970295884456, 'entropy': 0.7978866217506246}, 'active_entropy': 0.7824332310821873, 'chosen_targets': [1, 5, 2, 5, 2, 5, 0, 5, 2, 6], 'chosen_samples': [676, 39427, 28920, 34952, 2648, 44106, 52047, 16533, 53076, 22561], 'chosen_samples_score': [0.8325478742406693, 1.0823143161684277, 1.4531649900418775, 1.5447923102904548, 1.5849429754796485, 1.592851239349776, 1.6086795044237845, 1.6125447621556006, 1.6216901250981692, 1.6134088667095723], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.3086884030053625, 'batch_acquisition_elapsed_time': 264.40075205899484, 'prior_pool_entropy': 0.8464226254846425, 'batch_pool_mi': 0.5353852403798198})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8977, 'nll': 0.4477521989752311, 'entropy': 0.8595142749156522}, 'active_entropy': 0.8526078213427581, 'chosen_targets': [7, 4, 5, 3, 6, 5, 3, 2, 5, 6], 'chosen_samples': [1589, 2034, 51764, 57474, 50811, 24250, 43783, 42538, 21550, 15450], 'chosen_samples_score': [0.5686528635378447, 1.0228566114282756, 1.296088393727997, 1.462007365717775, 1.5322006047430454, 1.5615134043859271, 1.589471995058224, 1.5863859253223023, 1.5959674867099372, 1.6014045605455554], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.4342653900021105, 'batch_acquisition_elapsed_time': 263.4856181570067, 'prior_pool_entropy': 0.8973276479059483, 'batch_pool_mi': 0.5193071609396864})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8931, 'nll': 0.47642666733308126, 'entropy': 0.8878022496438663}, 'active_entropy': 0.9902637358861249, 'chosen_targets': [8, 3, 8, 2, 7, 8, 2, 5, 3, 5], 'chosen_samples': [726, 46570, 23458, 42323, 52666, 31124, 21674, 21204, 8756, 38944], 'chosen_samples_score': [0.7603720312046705, 0.9488036884047293, 1.3037935411329058, 1.4792199621502111, 1.5531377307084115, 1.5764013243624966, 1.591554121913111, 1.6101436630419919, 1.6007980447720245, 1.6232655084848036], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.350731127000472, 'batch_acquisition_elapsed_time': 264.9349926559953, 'prior_pool_entropy': 0.9821253195584844, 'batch_pool_mi': 0.65602056868527})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.9123, 'nll': 0.4519673270014979, 'entropy': 0.893591808807903}, 'active_entropy': 0.9399533318673302, 'chosen_targets': [8, 6, 0, 6, 9, 4, 8, 6, 7, 2], 'chosen_samples': [1593, 47631, 32880, 8826, 48766, 35946, 59361, 14147, 42828, 27120], 'chosen_samples_score': [0.8412792934633181, 1.1579286617658249, 1.498401740904842, 1.5708411303958099, 1.597816190850891, 1.613370415671819, 1.5938279275051253, 1.6049270114200045, 1.6099236218370296, 1.6235082948276913], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.234229326997593, 'batch_acquisition_elapsed_time': 263.881713777002, 'prior_pool_entropy': 1.0275675393834165, 'batch_pool_mi': 0.6140045762348065})
store['iterations'].append({'num_epochs': 1, 'test_metrics': {'accuracy': 0.8818, 'nll': 0.5265595422988572, 'entropy': 0.9697708368993768}, 'active_entropy': 0.8160594734179681, 'chosen_targets': [1, 6, 3, 2, 4, 0, 0, 2, 6, 8], 'chosen_samples': [1115, 25520, 3824, 13508, 828, 56388, 43602, 16909, 4231, 38539], 'chosen_samples_score': [0.8063763304302722, 0.9939909662442662, 1.4448548067618923, 1.545753667020571, 1.5873889385712538, 1.6045407995254575, 1.606019497372492, 1.6141900835949081, 1.617587946963552, 1.6012408975953738], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 5.379729209002107, 'batch_acquisition_elapsed_time': 263.8208305010048, 'prior_pool_entropy': 0.8963964796084116, 'batch_pool_mi': 0.5274620027637533})
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.mnist', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[35845, 27522, 33254, 16178, 11299, 57358, 58355, 26559, 27002, 41548, 33583, 45005, 58401, 7110, 17862, 28517, 54842, 24460, 23765, 46903]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
store = {}
store['args']={'experiment_task_id': None, 'experiments_laaos': None, 'experiment_description': 'Trying stuff..', 'batch_size': 4, 'gpu': 0, 'scoring_batch_size': 256, 'test_batch_size': 256, 'validation_set_size': 128, 'early_stopping_patience': 1, 'epochs': 1, 'epoch_samples': 5056, 'num_inference_samples': 5, 'available_sample_k': 10, 'target_num_acquired_samples': 800, 'target_accuracy': 0.98, 'no_cuda': False, 'quickquick': False, 'seed': 1, 'fix_numpy_python_seed': False, 'cudnn_deterministic': False, 'log_interval': 10, 'initial_samples_per_class': 2, 'initial_samples': None, 'file_with_initial_samples': '', 'type': 'AcquisitionFunction.bald', 'acquisition_method': 'AcquisitionMethod.multibald', 'dataset': 'DatasetEnum.cifar', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': False, 'balanced_test_set': False, 'hsic_compute_batch_size': 1000, 'max_batch_compute_size': 20, 'ical_max_greedy_iterations': 0, 'hsic_resample': True, 'hsic_kernel_name': 'mixrq', 'fass_entropy_bag_size_factor': 30, 'max_num_batch_init_samples_to_read': 10, 'num_to_condense': 200, 'num_inference_for_marginal_stat': 0, 'random_ical_minibatch': False, 'use_orig_condense': False}
store['cmdline']=['/home/cjiang/PycharmProjects/ALLib/run_experiment.py']
store['iterations']=[]
store['initial_samples']=[45845, 45348, 11799, 23564, 43880, 41303, 43701, 12631, 47144, 20588, 26988, 26603, 47233, 575, 48790, 37353, 4044, 36532, 37427, 22311]
